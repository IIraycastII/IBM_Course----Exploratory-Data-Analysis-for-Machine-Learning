Lecture-31
Type 1 vs Type 2 Error

Concept Overview:
In this section, we explore the Neyman-Pearson hypothesis testing framework, focusing on Type I and Type II errors, test power, and a real-world business example to illustrate their implications. This approach is non-Bayesian, meaning it evaluates hypotheses purely from sample data without incorporating prior beliefs.

1. Core Concepts
Hypothesis Testing Setup

Null Hypothesis (ğ»0): The default assumption â€” e.g., â€œthe coin is fairâ€ or â€œthere is no relationship.â€

Alternative Hypothesis (ğ»1): Represents the effect or difference weâ€™re testing for â€” e.g., â€œthe coin is biasedâ€ or â€œcustomers with longer tenure are less likely to churn.â€

Two Possible Errors
Error Type	Definition	Example
Type I Error (False Positive)	Rejecting the null hypothesis when it is actually true.	Concluding the coin is biased when it is, in fact, fair.
Type II Error (False Negative)	Failing to reject the null hypothesis when it is actually false.	Concluding the coin is fair when it is actually biased.
2. Test Power

The power of a test is defined as:

Power=1âˆ’ğ‘ƒ(Type II Error)
Power=1âˆ’P(Type II Error)

It measures the probability of correctly rejecting the null hypothesis when it is false â€” i.e., detecting a true effect.

High Power â†’ More likely to catch true effects, but may increase Type I errors if the threshold for rejection is too lenient.

Low Power â†’ Safer from false positives but more likely to miss real effects.

Trade-off: Increasing sensitivity to detect an effect (higher power) usually raises the risk of false alarms (Type I errors).

3. Illustrative Example â€” Coin Toss

ğ»0: The coin is fair (ğ‘=0.5 p=0.5).

ğ»1â€‹: The coin is biased (ğ‘â‰ 0.5, p=0.5).

Type I Error: Declaring the coin biased when itâ€™s actually fair.

Type II Error: Declaring the coin fair when itâ€™s actually biased.

Adjusting the rejection threshold (e.g., how extreme our results must be) changes the balance between Type I and Type II errors.

4. Real-World Example â€” Customer Churn Prediction
Scenario:

A business wants to predict whether long-term customers (over 2 years) are less likely to churn.

Null Hypothesis (ğ»0): Churn behavior is due to chance â€” tenure has no effect.

Alternative Hypothesis (ğ»1): Customers with >2 years tenure are less likely to churn.

Error Interpretations:
Error Type	What It Means	Business Consequence
Type I Error	Incorrectly rejecting ğ»0
	â€‹

 â†’ Concluding tenure affects churn when it doesnâ€™t.	Misallocating resources toward loyalty programs that donâ€™t truly reduce churn.
Type II Error	Failing to reject ğ»0

	â€‹

 â†’ Missing a real effect of tenure on churn.	Losing long-term customers due to not investing in retention strategies that actually work.
Power of the Test:

A powerful model would correctly detect that tenure affects churn (reject ğ»0 when ğ»1 is true).

The cutoff criteria (e.g., significance level 
ğ›¼
Î±) determine the balance between detecting true effects and avoiding false positives.

5. Key Takeaways

Type I Error (Î±): False alarm â€” finding an effect that isnâ€™t real.

Type II Error (Î²): Missed detection â€” failing to find a real effect.

Power (1 - Î²): Ability to correctly detect true effects.

Choosing the right balance between Î± and Î² depends on context â€” in medicine, avoiding Type I errors might be crucial; in marketing, minimizing Type II errors could be more valuable.
