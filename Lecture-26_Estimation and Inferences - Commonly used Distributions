Lecture 26: 
Estimation and Inferences - Commonly used Distributions

Learning Goals

In this lecture, weâ€™ll explore two major schools of thought in statistics:
Frequentist and Bayesian.

By the end, youâ€™ll understand how both frameworks approach uncertainty, probability, and inference â€” and how they differ in interpreting the same data.

1. Two Views of Probability

At the heart of this topic lies a philosophical difference in how each framework defines probability:

Perspective	Definition of Probability	Example Interpretation
Frequentist	Long-run frequency of events	â€œIf we flip this coin 1,000 times, the probability of heads is the proportion of heads we observe.â€
Bayesian	Degree of belief (subjective probability)	â€œBased on what I know, I believe thereâ€™s a 60% chance this coin will land heads.â€
2. The Frequentist Approach

In the Frequentist framework:

Probability is objective and based on repeated experiments.

Parameters (like the mean or proportion) are fixed but unknown constants.

Data is considered random, because itâ€™s drawn from a population.

You donâ€™t talk about â€œthe probability that a parameter is X.â€
Instead, you talk about the probability of seeing your data given that parameter.

Formally, Frequentists compute:

ğ‘ƒ
(
Data
âˆ£
Parameter
)
P(Dataâˆ£Parameter)

That is â€” â€œGiven a true parameter, what is the probability that we observed this data?â€

Example:

Suppose we want to estimate the average customer spending.
A Frequentist would say:

â€œThe true mean spending exists, but we donâ€™t know it. Letâ€™s estimate it from our sample.â€

They would compute a confidence interval, which tells us:

â€œIf we repeated this sampling process 100 times, the true mean would fall inside this range about 95 times.â€

3. The Bayesian Approach

In the Bayesian framework:

Probability reflects our belief or uncertainty about parameters.

Parameters are random variables with their own probability distributions.

We update our beliefs as new data comes in â€” using Bayesâ€™ theorem.

The formula is:
ğ‘ƒ(Parameterâˆ£Data)=ğ‘ƒ(Dataâˆ£Parameter)Ã—ğ‘ƒ(Parameter)ğ‘ƒ(Data)
P(Parameterâˆ£Data)=P(Data)P(Dataâˆ£Parameter)Ã—P(Parameter)
	â€‹


Hereâ€™s what each term means:

Term	Meaning

ğ‘ƒ(Parameter)
P(Parameter)	Prior â€” what we believed before seeing any data
ğ‘ƒ(Dataâˆ£Parameter)
P(Dataâˆ£Parameter)	Likelihood â€” how probable the data is, given a certain parameter
ğ‘ƒ(Parameterâˆ£Data)
P(Parameterâˆ£Data)	Posterior â€” updated belief after seeing data
ğ‘ƒ(Data)
P(Data)	Normalizing constant to ensure probabilities sum to 1
Example:

Imagine you run an online store and you believe that 5% of customers churn per month.
Thatâ€™s your prior belief.

After observing a month of data showing 8% churn, you update your belief:

â€œGiven this new data, I now believe the churn rate is likely between 6% and 9%.â€

That updated belief is your posterior.

4. Key Differences Between the Two
Concept	Frequentist	Bayesian
Probability Interpretation	Long-run frequency of outcomes	Degree of belief
Parameters	Fixed but unknown constants	Random variables with distributions
Data	Random sample	Observed evidence used to update beliefs
Output	Confidence intervals, p-values	Posterior distributions
New Data Handling	Entire analysis redone	Use Bayesâ€™ theorem to update prior
Example Tool	t-tests, ANOVA, regression	Bayesian inference, MCMC, posterior sampling
5. Real-World Business Example

Letâ€™s revisit customer churn prediction.

Frequentist View:

You estimate churn probability using logistic regression.

You compute confidence intervals for coefficients.

You state: â€œWith 95% confidence, tenure has a negative impact on churn.â€

Bayesian View:

You assign priors â€” e.g., â€œCustomers with higher tenure are likely to stay.â€

You update this belief as new churn data arrives each month.

You can continuously refine your posterior distribution for churn probability.

This makes the Bayesian approach particularly powerful in dynamic environments, like real-time analytics or financial forecasting.

6. When to Use Each
Situation	Recommended Approach
Large datasets with simple models	Frequentist (faster, fewer assumptions)
Small datasets or complex models	Bayesian (can incorporate prior knowledge)
Real-time updating or sequential learning	Bayesian
Classical hypothesis testing	Frequentist
